{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA and SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD THE DATASET\n",
    "\n",
    "#### Using the Bank Note Authentication Dataset - http://archive.ics.uci.edu/ml/datasets/banknote+authentication#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(variance=3.6216, skewness=8.6661, curtosis=-2.8073, entropy=-0.44699, class=0)\n",
      "root\n",
      " |-- variance: double (nullable = true)\n",
      " |-- skewness: double (nullable = true)\n",
      " |-- curtosis: double (nullable = true)\n",
      " |-- entropy: double (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "banknoteDataset = spark.read.csv(\"data_banknote_authentication.csv\", sep=',',inferSchema=True)\\\n",
    "        .toDF('variance','skewness','curtosis','entropy','class')\n",
    "print(banknoteDataset.head())\n",
    "print(banknoteDataset.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+-----+\n",
      "|variance|skewness|curtosis| entropy|class|\n",
      "+--------+--------+--------+--------+-----+\n",
      "|  3.6216|  8.6661| -2.8073|-0.44699|    0|\n",
      "|  4.5459|  8.1674| -2.4586| -1.4621|    0|\n",
      "|   3.866| -2.6383|  1.9242| 0.10645|    0|\n",
      "|  3.4566|  9.5228| -4.0112| -3.5944|    0|\n",
      "| 0.32924| -4.4552|  4.5718| -0.9888|    0|\n",
      "+--------+--------+--------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "banknoteDataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|          variance|          skewness|          curtosis|           entropy|             class|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|              1372|              1372|              1372|              1372|              1372|\n",
      "|   mean|0.4337352570699707|1.9223531206393603|1.3976271172667651|-1.191656520043731|0.4446064139941691|\n",
      "| stddev|2.8427625862785577| 5.869046743695513| 4.310030090106595| 2.101013137359609|0.4971032701256608|\n",
      "|    min|           -7.0421|          -13.7731|           -5.2861|           -8.5482|                 0|\n",
      "|    max|            6.8248|           12.9516|           17.9274|            2.4495|                 1|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "banknoteDataset.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler(\\\n",
    "inputCols=['variance','skewness','curtosis','entropy'],\\\n",
    "outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+-----+--------------------+\n",
      "|variance|skewness|curtosis| entropy|class|            features|\n",
      "+--------+--------+--------+--------+-----+--------------------+\n",
      "|  3.6216|  8.6661| -2.8073|-0.44699|    0|[3.6216,8.6661,-2...|\n",
      "|  4.5459|  8.1674| -2.4586| -1.4621|    0|[4.5459,8.1674,-2...|\n",
      "|   3.866| -2.6383|  1.9242| 0.10645|    0|[3.866,-2.6383,1....|\n",
      "+--------+--------+--------+--------+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp = vector_assembler.transform(banknoteDataset)\n",
    "df_temp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[3.6216,8.6661,-2...|\n",
      "|    0|[4.5459,8.1674,-2...|\n",
      "|    0|[3.866,-2.6383,1....|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_temp.drop('variance','skewness','curtosis','entropy')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "l_indexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|class|            features|classIndex|\n",
      "+-----+--------------------+----------+\n",
      "|    0|[3.6216,8.6661,-2...|       0.0|\n",
      "|    0|[4.5459,8.1674,-2...|       0.0|\n",
      "|    0|[3.866,-2.6383,1....|       0.0|\n",
      "|    0|[3.4566,9.5228,-4...|       0.0|\n",
      "|    0|[0.32924,-4.4552,...|       0.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = l_indexer.fit(df).transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------+\n",
      "|class|pcaFeatures                               |\n",
      "+-----+------------------------------------------+\n",
      "|0    |[-9.141988498528022,1.2645621038281543]   |\n",
      "|0    |[-8.824158431686138,1.581502362136377]    |\n",
      "|0    |[2.666160645333471,3.2646675009851416]    |\n",
      "|0    |[-10.932646142995985,-0.13002268423205332]|\n",
      "|0    |[5.93351057287925,-0.3742398697901879]    |\n",
      "|0    |[-11.091338074506377,0.7384944056852125]  |\n",
      "|0    |[-2.46530968170101,2.117200228644701]     |\n",
      "|0    |[9.788932914931099,0.6627925029521695]    |\n",
      "|0    |[-5.62191772112166,1.0048879097449603]    |\n",
      "|0    |[-9.00956346569529,-0.8317760598330879]   |\n",
      "|0    |[-8.620424611259098,-1.0249334460642896]  |\n",
      "|0    |[3.0726725110414987,3.5767457355450856]   |\n",
      "|0    |[-6.845357453759397,-1.9247461302046134]  |\n",
      "|0    |[-7.592075903959261,-6.191420634596226]   |\n",
      "|0    |[-9.279433134932228,1.073876390553459]    |\n",
      "|0    |[4.220571981332124,4.251206933513333]     |\n",
      "|0    |[-2.570789612041451,1.4835140687001487]   |\n",
      "|0    |[0.054798366672089996,-1.1436894586592925]|\n",
      "|0    |[8.029711382335385,-0.9955878318296442]   |\n",
      "|0    |[-12.665263663739271,0.7828389705995287]  |\n",
      "+-----+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform PCA\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "bankPCA = PCA(k=2, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "pcaModel = bankPCA.fit(df)\n",
    "pcaResult = pcaModel.transform(df).select(\"class\",\"pcaFeatures\")\n",
    "pcaResult.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------+\n",
      "|class|pcaFeatures                               |\n",
      "+-----+------------------------------------------+\n",
      "|0    |[-9.141988498528022,1.2645621038281543]   |\n",
      "|0    |[-8.824158431686138,1.581502362136377]    |\n",
      "|0    |[2.666160645333471,3.2646675009851416]    |\n",
      "|0    |[-10.932646142995985,-0.13002268423205332]|\n",
      "|0    |[5.93351057287925,-0.3742398697901879]    |\n",
      "|0    |[-11.091338074506377,0.7384944056852125]  |\n",
      "|0    |[-2.46530968170101,2.117200228644701]     |\n",
      "|0    |[9.788932914931099,0.6627925029521695]    |\n",
      "|0    |[-5.62191772112166,1.0048879097449603]    |\n",
      "|0    |[-9.00956346569529,-0.8317760598330879]   |\n",
      "|0    |[-8.620424611259098,-1.0249334460642896]  |\n",
      "|0    |[3.0726725110414987,3.5767457355450856]   |\n",
      "|0    |[-6.845357453759397,-1.9247461302046134]  |\n",
      "|0    |[-7.592075903959261,-6.191420634596226]   |\n",
      "|0    |[-9.279433134932228,1.073876390553459]    |\n",
      "|0    |[4.220571981332124,4.251206933513333]     |\n",
      "|0    |[-2.570789612041451,1.4835140687001487]   |\n",
      "|0    |[0.054798366672089996,-1.1436894586592925]|\n",
      "|0    |[8.029711382335385,-0.9955878318296442]   |\n",
      "|0    |[-12.665263663739271,0.7828389705995287]  |\n",
      "+-----+------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "bankPCA = PCA(k=2, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "pcaModel = bankPCA.fit(df)\n",
    "pcaResult = pcaModel.transform(df).select(\"class\",\"pcaFeatures\")\n",
    "pcaResult.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Vector\n",
      "[13.029275535600473,5.368578733451684,2.5330498218813755,6.323166049206486e-08,2.0226934557075942e-08]\n",
      "Dense matrix\n",
      "DenseMatrix([[-0.31278534,  0.31167136,  0.30366911,  0.8409913 , -0.07446478],\n",
      "             [-0.02980145, -0.17133211, -0.02226069,  0.14664984,  0.97352733],\n",
      "             [-0.12207248,  0.15256471, -0.95070998,  0.23828799, -0.03452092],\n",
      "             [-0.71847899, -0.68096285, -0.0172245 , -0.02094998, -0.13907533],\n",
      "             [-0.60841059,  0.62170723,  0.05606596, -0.46260933,  0.16175873]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "rows = sc.parallelize([\n",
    "    Vectors.sparse(5, {1: 1.0, 3: 7.0}),\n",
    "    Vectors.dense(2.0, 0.0, 3.0, 4.0, 5.0),\n",
    "    Vectors.dense(4.0, 0.0, 0.0, 6.0, 7.0)\n",
    "])\n",
    "\n",
    "mat = RowMatrix(rows)\n",
    "\n",
    "# Compute the top 5 singular values and corresponding singular vectors.\n",
    "svd = mat.computeSVD(5, computeU=True)\n",
    "# U is a RowMatrix.\n",
    "U = svd.U  \n",
    "# S is a dense vector.\n",
    "s = svd.s \n",
    "print('Dense Vector')\n",
    "print(s)\n",
    "# V is a dense matrix.\n",
    "V = svd.V  \n",
    "print('Dense matrix')\n",
    "print(V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
